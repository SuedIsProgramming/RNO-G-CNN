{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import hilbert\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTIONS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(name, path='/data/i3home/ssued/RNOGCnn'):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if name in files:\n",
    "            return os.path.join(root, name)\n",
    "        \n",
    "print(f'{find('event_dict.pkl')}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_relative_time(event, plot=False):\n",
    "    \"\"\"\n",
    "    Shift all channels in an event by the value of the first trigger signal time.\n",
    "\n",
    "    NOTE: Might be too expensive, as you have to search throughout all of the time arrays to find the minimum time value.\n",
    "    Perhaps its better to not search? Looking at the generated voltage vs. time arrays, all channel seem to have the same starting time?\n",
    "\n",
    "    Parameters:\n",
    "    event (np.array): Event containing channels with voltage vs. time arrays.\n",
    "    plot (bool): If True, generates before and after subplots (for debugging purposes).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Plot before the shift, if requested\n",
    "    if plot:\n",
    "        _, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        ax[0].plot(event[0][0], event[0][1])\n",
    "        ax[0].set_title('Before Shift')\n",
    "        ax[0].set_xlabel('Time')\n",
    "        ax[0].set_ylabel('Voltage')\n",
    "\n",
    "    # Find the minimum time across all channels\n",
    "    min_time = min(np.min(channel[0]) for channel in event)\n",
    "\n",
    "    # Subtract min_time from the time values of each channel\n",
    "    for channel in event:\n",
    "        channel[0] -= min_time\n",
    "\n",
    "    # Plot after the shift, if requested\n",
    "    if plot:\n",
    "        ax[1].plot(event[0][0], event[0][1])\n",
    "        ax[1].set_title('After Shift')\n",
    "        ax[1].set_xlabel('Time (ns)')\n",
    "        ax[1].set_ylabel('Voltage (V)')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('Before_and_after_shift.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_v(channel, nbins, hilbert = False, method='max', plot=False):\n",
    "    \"\"\"\n",
    "    Bin voltage vs. time data. The bin values are calculated according to different methods.\n",
    "\n",
    "    A big issue is that if the different channels effectively HAVE different time domains, then the different channels will contain\n",
    "    different bin sizes. We could make all bins the same size, but then graphs will have more or less bins, or we could keep it like this.\n",
    "    Parameters:\n",
    "    channel (np.array): Channel array containing two numpy arrays of time (pos [0]) and voltage (pos [1]).\n",
    "    method (str): Modifies bin values according to the method. \n",
    "                  'max' - Bins Hilbert envelope according to the local maximum of their respective time bins.\n",
    "                  'avg' - Bins Hilbert envelope according to the average of their respective time bins.\n",
    "    plot (bool): If True, plots the original Hilbert envelope and the binned data.\n",
    "\n",
    "    Returns:\n",
    "    np.array: Binned time array\n",
    "    np.array: Binned Hilbert envelope array\n",
    "    float: Time of a bin.\n",
    "    \"\"\"\n",
    "    \n",
    "    time_arr = channel[0]\n",
    "    voltage_arr = channel[1]\n",
    "\n",
    "    if hilbert is True:\n",
    "        # Obtain Hilbert envelope\n",
    "        v_arr = np.abs(hilbert(voltage_arr))\n",
    "    else:\n",
    "        v_arr = voltage_arr\n",
    "\n",
    "    bin_width = len(voltage_arr) // nbins\n",
    "    bin_dt = time_arr[bin_width]-time_arr[0]\n",
    "    binned_time = time_arr[:nbins * bin_width:bin_width]\n",
    "\n",
    "    if method == 'max':\n",
    "        binned = np.array([np.max(v_arr[i:i+bin_width]) for i in range(0, nbins * bin_width, bin_width)])\n",
    "    elif method == 'avg':\n",
    "        binned = np.array([np.mean(v_arr[i:i+bin_width]) for i in range(0, nbins * bin_width, bin_width)])\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid method '{method}'. Use 'max' or 'avg'.\")\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(time_arr, v_arr, label='Original Hilbert Envelope', alpha=0.7)\n",
    "        plt.plot(binned_time, binned, 'o-', label=f'Binned Hilbert Envelope ({method})', color='red')\n",
    "        plt.xlabel(f'Time (ns), one bin = {bin_dt} ns')\n",
    "        plt.ylabel('Hilbert Envelope (V)')\n",
    "        plt.title('Original vs Binned Hilbert Envelope')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig('Original vs Binned Hilbert Envelope.png')\n",
    "\n",
    "    return binned_time, binned, bin_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_noise(voltage_arr, plot=False):\n",
    "    \"\"\"\n",
    "    Calculate the RMS noise of a voltage array and optionally plot the voltage data.\n",
    "\n",
    "    The noise is calculated by:\n",
    "    1. Identifying the peak signal (maximum value) in the array.\n",
    "    2. Defining a range around the peak, covering 25% of the array's length to the left and right of the peak.\n",
    "    3. Extracting the noise subarrays from the portions of the array outside this range.\n",
    "    4. Calculating the RMS noise from the concatenated noise subarrays.\n",
    "\n",
    "    Parameters:\n",
    "    voltage_arr (np.array): Array of voltage values.\n",
    "    plot (bool): If True, plots the voltage data with noise range markers (For debugging purposes).\n",
    "\n",
    "    Returns:\n",
    "    float: The RMS noise value.\n",
    "    \"\"\"\n",
    "    \n",
    "    peak_idx = np.argmax(voltage_arr)\n",
    "    quarter_len = len(voltage_arr) // 4\n",
    "\n",
    "    # Define the range around the peak signal\n",
    "    left_idx = max(0, peak_idx - quarter_len)\n",
    "    right_idx = min(len(voltage_arr), peak_idx + quarter_len)\n",
    "\n",
    "    # Extract noise subarrays and concatenate them\n",
    "    noise_subarray = np.concatenate((voltage_arr[:left_idx], voltage_arr[right_idx:]))\n",
    "\n",
    "    # Calculate RMS noise\n",
    "    rms_noise = np.sqrt(np.mean(noise_subarray ** 2))\n",
    "\n",
    "    # For testing purposes:\n",
    "    if plot:\n",
    "        # Plotting the original voltage data\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(voltage_arr, label='Voltage Data', color='blue')\n",
    "        \n",
    "        # Mark the start and end indices of the noise range\n",
    "        plt.axvline(x=left_idx, color='red', linestyle='--', label='Left Noise Index')\n",
    "        plt.axvline(x=right_idx, color='green', linestyle='--', label='Right Noise Index')\n",
    "        \n",
    "        # Highlighting the noise areas on the plot\n",
    "        plt.fill_between(range(left_idx), voltage_arr[:left_idx], color='red', alpha=0.3)\n",
    "        plt.fill_between(range(right_idx, len(voltage_arr)), voltage_arr[right_idx:], color='green', alpha=0.3)\n",
    "        \n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Voltage (V)')\n",
    "        plt.title('Voltage Data with Noise Range')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig('Voltage Data with Noise Range.png')\n",
    "\n",
    "    return rms_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_matrix(event,bins = 25, plotting = False, hilb = False):\n",
    "    row1 = bin_v(event['data'][0],bins, hilbert = hilb)[1]\n",
    "    row2 = bin_v(event['data'][1],bins, hilbert = hilb)[1]\n",
    "    row3 = bin_v(event['data'][2],bins, hilbert = hilb)[1]\n",
    "    row4 = bin_v(event['data'][3],bins, hilbert = hilb)[1]\n",
    "    bintime = row1[3]\n",
    "    bintime_ns = bintime*(10**6)\n",
    "    matrix = np.array([row1,row2,row3,row4])\n",
    "\n",
    "    binned_dict = {'data' : matrix, 'bintime' : bintime_ns}\n",
    "\n",
    "    if plotting:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        # Creating the heatmap\n",
    "        plt.imshow(matrix, cmap='viridis', interpolation='nearest',aspect=5)\n",
    "        plt.colorbar()  # adding color bar to show the scale\n",
    "        plt.title(\"Heatmap of voltage on 4 channels\")\n",
    "        plt.xlabel(f\"Bin Value:{bintime_ns: .3g} ns    ;    Mean SNR:{event['mean_integrated_power']: .3g}\")\n",
    "        y_ticks = [0, 1, 2, 3]  # Custom y-tick positions\n",
    "        y_labels = ['Channel 1', 'Channel 2', 'Channel 3', 'Channel 4']  # Custom y-tick labels\n",
    "        plt.yticks(y_ticks, y_labels)\n",
    "        plt.show()\n",
    "\n",
    "    return binned_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(event):\n",
    "    matrix = event['data']\n",
    "    bintime_ns = event['bin_time']\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # Creating the heatmap\n",
    "    plt.imshow(matrix, cmap='viridis', interpolation='nearest',aspect=5)\n",
    "    plt.colorbar()  # adding color bar to show the scale\n",
    "    plt.title(\"Heatmap of voltage on 4 channels\")\n",
    "    plt.xlabel(f\"Bin Value:{bintime_ns: .3g} ns    ;    Mean SNR:{event['mean_SNR']: .3g}\")\n",
    "    y_ticks = [0, 1, 2, 3]  # Custom y-tick positions\n",
    "    y_labels = ['Channel 1', 'Channel 2', 'Channel 3', 'Channel 4']  # Custom y-tick labels\n",
    "    plt.yticks(y_ticks, y_labels)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "event_data_to_append = {}\n",
    "\n",
    "def save_events(file_path='data/event_data.pkl',events_in=None):\n",
    "    \"\"\"\n",
    "    Save events in a dictionary. If a dictionary already exists, it will append the events to the end of the dictionary.\n",
    "    Otherwise, it will create the pickled dictionary in the file_path.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (String) location of dictionary, or location where to create it.\n",
    "    events_in (dict) python dictionary from which to append the events or to save.\n",
    "    \"\"\"\n",
    "    # Check if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        # Load and return the dictionary\n",
    "        with open(file_path, 'rb') as file:\n",
    "            event_dict = pickle.load(file)\n",
    "\n",
    "        start_i = max(event_dict.keys())\n",
    "\n",
    "        # Function to shift keys by a given number\n",
    "        def shift_keys(d, shift_amount):\n",
    "            return {k + shift_amount: v for k, v in d.items()}\n",
    "        \n",
    "        shifted_events_in = shift_keys(events_in,start_i+1)\n",
    "        new_event_dict = {**event_dict, **shifted_events_in}\n",
    "\n",
    "        with open(file_path, 'wb') as file:\n",
    "            pickle.dump(new_event_dict, file)\n",
    "    else:\n",
    "        # Save the event dictionary to file\n",
    "        with open(file_path, 'wb') as file:\n",
    "            pickle.dump(events_in, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_SNR(matrix, plot = False):\n",
    "    SNR = 0\n",
    "    for i,channel in enumerate(matrix):\n",
    "        SNR += np.max(channel)/calculate_noise(channel, plot)\n",
    "\n",
    "    SNR_mean = SNR/4\n",
    "\n",
    "    return SNR_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raw(event):\n",
    "    # Create subplots: 2 rows, 2 columns (for 4 channels)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    axes = axes.flatten()  # Flatten the axes array for easier indexing\n",
    "\n",
    "    event = event['data']\n",
    "\n",
    "    # Loop through the first 4 channels and plot their data\n",
    "    for i,ch in enumerate(event):  # Assuming there are at least 4 channels\n",
    "        time = ch[0]  # Time values for the channel\n",
    "        voltage = ch[1]  # Voltage values for the channel\n",
    "\n",
    "        # Plot the time vs voltage for each channel in the appropriate subplot\n",
    "        axes[i].plot(time, voltage)\n",
    "        axes[i].set_title(f'Channel {i + 1}')\n",
    "        axes[i].set_xlabel('Time (s)')\n",
    "        axes[i].set_ylabel('Voltage (V)')\n",
    "    \n",
    "    # Adjust layout to avoid overlapping labels\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage with event data\n",
    "# event = [ [ [time1, voltage1], [time2, voltage2], ... ], ... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear out eventbatch function. Might be useless. Lol.\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "def new_eventbatch(save_old=True, eventdata_path = '/data/i3home/ssued/RNOGCnn/CNN_steps/eventdata'):\n",
    "    \"\"\"\n",
    "    Create a new event batch. If save_old is True, it will save the current event batch to the event_data.pkl file.\n",
    "\n",
    "    Parameters:\n",
    "    save_old (bool): If True, saves the current event batch to eventbatch_old_year_month.pkl.\n",
    "    \"\"\"\n",
    "\n",
    "    # Save the current event batch to eventbatch_old.pkl\n",
    "    if save_old:\n",
    "        with open(f'{eventdata_path}/eventbatch.pkl', 'rb') as file:\n",
    "            old_eventbatch = pickle.load(file)\n",
    "\n",
    "        current_date = datetime.now().strftime(\"%Y_%m_%d\")\n",
    "        with open(f'{eventdata_path}/eventbatch_old_{current_date}.pkl', 'wb') as file:\n",
    "            pickle.dump(old_eventbatch, file)\n",
    "\n",
    "    # Clear eventbatch\n",
    "    eventbatch = {}\n",
    "\n",
    "    with open(f'{eventdata_path}/eventbatch.pkl', 'wb') as file:\n",
    "        pickle.dump(eventbatch, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_evb(eventbatch : str, eventdata_folder : str = '/data/i3home/ssued/RNOGCnn/CNN_steps/eventdata'):\n",
    "    \"\"\"\n",
    "    Quality of life function. Simply return event batch dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    eventbatch (dict): Event dictionary to inspect.\n",
    "    eventdata_folder (str): Folder where the eventbatch is stored.\n",
    "    \"\"\"\n",
    "\n",
    "    if not eventbatch.endswith('.pkl'):\n",
    "        eventbatch = f'{eventbatch}.pkl'\n",
    "    with open(f'{eventdata_folder}/{eventbatch}', 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "ev = obtain_evb('eventbatch')\n",
    "\n",
    "ev.keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For image plotting!\n",
    "\n",
    "with open('/data/i3home/ssued/RNOGCnn/CNN_steps/eventdata/eventbatch.pkl', 'rb') as file:\n",
    "    event_dict = pickle.load(file)\n",
    "\n",
    "event = event_dict[0]\n",
    "\n",
    "plot_image(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {0:'a',1:'b',2:'c',3:'d'}\n",
    "dict_in = {0:'e',1:'f'}\n",
    "\n",
    "start_i = max(dict.keys())\n",
    "\n",
    "for k, v in dict_in.items():\n",
    "    dict[start_i + k + 1] = v\n",
    "\n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append('/data/i3home/ssued/RNOGCnn')\n",
    "import utils\n",
    "\n",
    "os.chdir('/data/i3home/ssued/RNOGCnn/function_testing')\n",
    "\n",
    "# test_batch = {0:'a',1:'b',2:'c'}\n",
    "# with open('testing_merge/test_batch.pkl', 'wb') as file:\n",
    "#     pickle.dump(test_batch, file)\n",
    "\n",
    "test_1 = {0:'d',1:'e'}\n",
    "with open('testing_merge/test_1.pkl', 'wb') as file:\n",
    "    pickle.dump(test_1, file)\n",
    "\n",
    "test_2 = {0:'f',1:'g'}\n",
    "with open('testing_merge/test_2.pkl', 'wb') as file:\n",
    "    pickle.dump(test_2, file)\n",
    "\n",
    "test_3 = {0:'h',1:'i'}\n",
    "with open('testing_merge/test_3.pkl', 'wb') as file:\n",
    "    pickle.dump(test_3, file)\n",
    "\n",
    "#utils.merge_events(file_path='testing_merge/test_batch.pkl',input_path='testing_merge/test_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append('/data/i3home/ssued/RNOGCnn')\n",
    "import utils\n",
    "\n",
    "os.chdir('/data/i3home/ssued/RNOGCnn/function_testing/testing_merge')\n",
    "\n",
    "for file_name in os.listdir(os.getcwd()):\n",
    "    if not file_name.endswith('batch.pkl'):\n",
    "        utils.conjoin_events(input_path=file_name, file_path='test_batch.pkl')\n",
    "\n",
    "with open('test_batch.pkl', 'rb') as file:\n",
    "    test_batch = pickle.load(file)\n",
    "\n",
    "print(test_batch.keys())\n",
    "for value in test_batch.values():\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/data/i3home/ssued/RNOGCnn/CNN_steps/eventdata/eventbatch.pkl', 'rb') as file:\n",
    "    evb = pickle.load(file)\n",
    "\n",
    "evb.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append('/data/i3home/ssued/RNOGCnn')\n",
    "import utils\n",
    "\n",
    "os.chdir('/data/i3home/ssued/RNOGCnn/function_testing')\n",
    "\n",
    "#test_batch = {0:'a',1:'b',2:'c'}\n",
    "with open('testing_merge/test_batch.pkl', 'rb') as file:\n",
    "    test_batch = pickle.load(file)\n",
    "# #test_1 = {0:'d',1:'e'}\n",
    "# with open('testing_merge/test_1.pkl', 'rb') as file:\n",
    "#     test_1 = pickle.load(file)\n",
    "#     print(test_1.keys())\n",
    "# #test_2 = {0:'f',1:'g'}\n",
    "# with open('testing_merge/test_2.pkl', 'rb') as file:\n",
    "#     test_2 = pickle.load(file)\n",
    "#     print(test_2.keys())\n",
    "\n",
    "\n",
    "\n",
    "#merge_events(file_path='testing_merge/test_batch.pkl',input_path='testing_merge/test_2.pkl')\n",
    "\n",
    "#time.sleep(5)\n",
    "\n",
    "print(test_batch.keys())\n",
    "for value in test_batch.values():\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated SNR values found:\n",
      "SNR: 3.5846768572577563, Count: 4\n",
      "SNR: 3.627613660699147, Count: 4\n",
      "SNR: 3.659114176609958, Count: 4\n",
      "SNR: 3.801126777444452, Count: 4\n",
      "SNR: 3.671666622553848, Count: 4\n",
      "SNR: 5.10557212776405, Count: 3\n",
      "SNR: 9.598411610443145, Count: 3\n",
      "SNR: 3.4721809052289956, Count: 3\n",
      "SNR: 3.455244321595024, Count: 3\n",
      "SNR: 3.9426966058277677, Count: 3\n",
      "SNR: 11.94980191519963, Count: 4\n",
      "SNR: 11.298217091891058, Count: 4\n",
      "SNR: 7.5353890474058485, Count: 3\n",
      "SNR: 3.709964447878656, Count: 4\n",
      "SNR: 3.4917503287398084, Count: 4\n",
      "SNR: 3.7632942333350297, Count: 3\n",
      "SNR: 3.8127424035531856, Count: 3\n",
      "SNR: 4.500213512598476, Count: 3\n",
      "SNR: 28.33304718828407, Count: 3\n",
      "SNR: 7.061293677141073, Count: 2\n",
      "SNR: 3.7223495253909804, Count: 4\n",
      "SNR: 3.5144131736592095, Count: 3\n",
      "SNR: 3.5075680162013776, Count: 3\n",
      "SNR: 67.82052844664614, Count: 2\n",
      "SNR: 3.2799014465739846, Count: 4\n",
      "SNR: 3.523519865109047, Count: 2\n",
      "SNR: 6.647110084491207, Count: 2\n",
      "SNR: 109.7476088776859, Count: 3\n",
      "SNR: 3.509031515357264, Count: 3\n",
      "SNR: 3.5184015211800683, Count: 2\n",
      "Total repeated SNR values: 96\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import sys\n",
    "sys.path.append('/data/i3home/ssued/RNOGCnn')\n",
    "import utils\n",
    "\n",
    "#utils.merge_events(input_path='/data/i3home/ssued/RNOGCnn/CNN_steps/eventdata/eventbatch_2.pkl'\n",
    "#                   ,file_path='/data/i3home/ssued/RNOGCnn/CNN_steps/eventdata/eventbatch.pkl')\n",
    "\n",
    "with open('/data/i3home/ssued/RNOGCnn/CNN_steps/eventdata/eventbatch.pkl','rb') as file:\n",
    "    evb = pickle.load(file)\n",
    "    \n",
    "snr_values = [value['mean_SNR'] for value in evb.values()]\n",
    "repeated_snr = set([snr for snr in snr_values if snr_values.count(snr) > 1])\n",
    "\n",
    "if repeated_snr:\n",
    "    print(\"Repeated SNR values found:\")\n",
    "    sum = 0\n",
    "    for snr in repeated_snr:\n",
    "        print(f\"SNR: {snr}, Count: {snr_values.count(snr)}\")\n",
    "        sum += snr_values.count(snr)\n",
    "\n",
    "    print(f\"Total repeated SNR values: {sum}\")\n",
    "else:\n",
    "    print(\"No repeated SNR values found.\")\n",
    "\n",
    "# IMPORTANT! FOR CHECKING REPEATED SNRS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "def save_events_test(directory='/data/i3home/ssued/RNOGCnn/function_testing/data/', event_in = None):\n",
    "    \"\"\"\n",
    "    Save a file in the directory with a numerical suffix based on existing files.\n",
    "    If no files exist, it saves as 'trace_0.pkl'. Otherwise, it finds the highest numerical suffix,\n",
    "    increments it, and saves the file.\n",
    "\n",
    "    Parameters:\n",
    "    directory (str): Directory to save the file.\n",
    "    event_in (str): Event content to save in the file.\n",
    "    \"\"\"\n",
    "    base_name = \"trace\"\n",
    "    ext = \".pkl\"\n",
    "    max_suffix = -1\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Iterate through the files in the directory to find the highest numerical suffix\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.startswith(base_name) and file_name.endswith(ext):\n",
    "            try:\n",
    "                # Extract the number after the base_name and before the extension\n",
    "                suffix = int(file_name[len(base_name) + 1: -len(ext)])\n",
    "                max_suffix = max(max_suffix, suffix)\n",
    "            except ValueError:\n",
    "                # Ignore files that don't follow the naming pattern\n",
    "                pass\n",
    "\n",
    "    # Determine the new file name\n",
    "    new_suffix = max_suffix + 1\n",
    "    new_file_name = f\"{base_name}_{new_suffix}{ext}\"\n",
    "    new_file_path = os.path.join(directory, new_file_name)\n",
    "\n",
    "    # Save the text content to the new file\n",
    "    with open(new_file_path, 'wb') as file:\n",
    "        pickle.dump(event_in, file)\n",
    "\n",
    "    print(f\"File saved as: {new_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssued",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
